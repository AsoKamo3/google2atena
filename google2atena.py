# google2atena.py (ä¿®æ­£ç‰ˆ)
import io, re, csv, os
from flask import Flask, render_template, request, send_file, abort, Response

app = Flask(__name__)

# =========================
# æ–‡å­—ç¨®å¤‰æ›ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================

FULLWIDTH_OFFSET = ord("ï¼") - ord("!")
ASCII_MIN, ASCII_MAX = 33, 126

def to_zenkaku(s: str) -> str:
    if not isinstance(s, str): return ""
    out = []
    for ch in s:
        code = ord(ch)
        if ch == " ":
            out.append("ã€€")
        elif 33 <= code <= 126:
            out.append(chr(code + FULLWIDTH_OFFSET))
        else:
            out.append(ch)
    return "".join(out)

def to_hankaku_simple(s: str) -> str:
    if not isinstance(s, str): return ""
    out = []
    for ch in s:
        if ch == "ã€€":
            out.append(" ")
            continue
        code = ord(ch)
        if 65281 <= code <= 65374:
            out.append(chr(code - FULLWIDTH_OFFSET))
        else:
            out.append(ch)
    return "".join(out)

def normalize_for_phone_email_postal(s: str) -> str:
    s = (s or "")
    s = to_hankaku_simple(s)
    return s.strip()

# =========================
# ä¼šç¤¾åã®æ³•äººæ ¼ã‚¹ãƒšãƒ¼ã‚¹å‡¦ç†
# =========================

CORP_PREFIXES = [
    "æ ªå¼ä¼šç¤¾", "æœ‰é™ä¼šç¤¾", "åˆåŒä¼šç¤¾",
    "ä¸€èˆ¬ç¤¾å›£æ³•äºº", "ä¸€èˆ¬è²¡å›£æ³•äºº",
    "å…¬ç›Šç¤¾å›£æ³•äºº", "å…¬ç›Šè²¡å›£æ³•äºº",
    "ç¤¾å›£æ³•äºº", "è²¡å›£æ³•äºº",
]

def insert_space_after_corp_prefix(name: str) -> str:
    s = name or ""
    for p in CORP_PREFIXES:
        if s.startswith(p):
            rest = s[len(p):]
            if rest.startswith("ã€€"):
                return s
            rest = rest.lstrip(" ")
            return p + "ã€€" + rest
    return s

# =========================
# ä½æ‰€æ­£è¦åŒ–
# =========================

BUILDING_KEYWORDS = [
    "ãƒ“ãƒ«", "ãƒãƒ³ã‚·ãƒ§ãƒ³", "ãƒã‚¤ãƒ„", "ã‚¢ãƒ‘ãƒ¼ãƒˆ", "ã‚³ãƒ¼ãƒ",
    "ã‚¿ãƒ¯ãƒ¼", "ãƒ’ãƒ«ã‚º", "è˜", "ãƒ¬ã‚¸ãƒ‡ãƒ³ã‚¹", "ãƒã‚¦ã‚¹", "ãƒ†ãƒ©ã‚¹", "ãƒ¡ã‚¾ãƒ³",
]

def unify_hyphen(s: str) -> str:
    return re.sub(r"[â€-â€“â€”âˆ’-]", "ï¼", s)

def zenkaku_digits(s: str) -> str:
    tbl = str.maketrans("0123456789", "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™")
    return s.translate(tbl)

def normalize_address(addr: str):
    if not addr: return "", ""
    s = addr.strip()
    s = to_zenkaku(s)
    s = unify_hyphen(s)
    s = zenkaku_digits(s)
    s = re.sub(r"([ï¼-ï¼™]+)\s*ä¸ç›®", r"\1ï¼", s)
    s = re.sub(r"([ï¼-ï¼™]+)\s*ç•ªåœ°?", r"\1ï¼", s)
    s = re.sub(r"([ï¼-ï¼™]+)\s*å·(å®¤)?", r"\1", s)
    s = re.sub(r"ï¼{2,}", "ï¼", s)

    has_building_word = any(k in s for k in BUILDING_KEYWORDS)
    building = ""

    m = re.search(rf"(.+?({'|'.join(BUILDING_KEYWORDS)}))\s*([ï¼-ï¼™]+)\s*éš", s)
    if m:
        base = s[:m.start()].rstrip()
        bname = m.group(1).strip()
        floor = m.group(3)
        building = f"ã€€{bname}ã€€{floor}ï¼¦"
        return base, building

    m = re.search(rf"(.+?({'|'.join(BUILDING_KEYWORDS)}))\s*([ï¼-ï¼™]{{1,4}})$", s)
    if m:
        base = s[:m.start()].rstrip()
        bname = m.group(1).strip()
        room = m.group(3)
        building = f"ã€€{bname}ã€€ï¼ƒ{room}"
        return base, building

    m = re.search(rf"(.+?({'|'.join(BUILDING_KEYWORDS)}))\s*([ï¼-ï¼™]{{1,4}})\s*å·å®¤", s)
    if m:
        base = s[:m.start()].rstrip()
        bname = m.group(1).strip()
        room = m.group(3)
        building = f"ã€€{bname}ã€€ï¼ƒ{room}"
        return base, building

    if ("ä¸ç›®" in addr) or ("ç•ª" in addr) or ("å·" in addr):
        m = re.search(r"(.+?)ï¼([ï¼-ï¼™]{3,})$", s)
        if m:
            base = m.group(1).rstrip()
            room = m.group(2)
            building = f"ã€€ï¼ƒ{room}"
            return base, building

    return s, ""

# =========================
# Google CSV ãƒ‘ãƒ¼ã‚¹
# =========================

def parse_google_row(row):
    get = lambda k: (row.get(k) or "").strip()
    first = get("First Name")
    middle = get("Middle Name")
    last = get("Last Name")
    pf_first = get("Phonetic First Name")
    pf_middle = get("Phonetic Middle Name")
    pf_last = get("Phonetic Last Name")
    nickname = get("Nickname")
    notes = get("Notes")
    birthday = get("Birthday")

    org = get("Organization Name")
    dept = get("Organization Department")
    title = get("Organization Title")

    emails = {"work": [], "home": [], "other": []}
    phones = {"work": [], "home": [], "other": []}

    for n in range(1, 50):
        tkey = f"E-mail {n} - Type"
        vkey = f"E-mail {n} - Value"
        if tkey in row or vkey in row:
            typ = get(tkey).strip().lower()
            val = get(vkey)
            if val:
                if typ in ("work", "å‹¤å‹™å…ˆ", "ä¼šç¤¾", "è·å ´"):
                    emails["work"].append(val)
                elif typ in ("home", "è‡ªå®…", "ãƒ›ãƒ¼ãƒ "):
                    emails["home"].append(val)
                else:
                    emails["other"].append(val)
        else:
            break

    for n in range(1, 50):
        tkey = f"Phone {n} - Type"
        vkey = f"Phone {n} - Value"
        if tkey in row or vkey in row:
            typ = get(tkey).strip().lower()
            val = get(vkey)
            if val:
                if typ in ("work", "å‹¤å‹™å…ˆ", "ä¼šç¤¾", "è·å ´"):
                    phones["work"].append(val)
                elif typ in ("home", "è‡ªå®…", "ãƒ›ãƒ¼ãƒ "):
                    phones["home"].append(val)
                else:
                    phones["other"].append(val)
        else:
            break

    addr = {"work": {"postal": "", "line": ""},
            "home": {"postal": "", "line": ""},
            "other": {"postal": "", "line": ""}}
    for n in range(1, 50):
        tkey = f"Address {n} - Type"
        reg = f"Address {n} - Region"
        city = f"Address {n} - City"
        street = f"Address {n} - Street"
        postal = f"Address {n} - Postal Code"
        if tkey in row or reg in row or city in row or street in row or postal in row:
            typ = get(tkey).strip().lower()
            line = " ".join([get(reg), get(city), get(street)]).strip()
            pcd = get(postal)
            if typ in ("work", "å‹¤å‹™å…ˆ", "ä¼šç¤¾", "è·å ´"):
                addr["work"]["postal"] = pcd or addr["work"]["postal"]
                addr["work"]["line"] = line or addr["work"]["line"]
            elif typ in ("home", "è‡ªå®…", "ãƒ›ãƒ¼ãƒ "):
                addr["home"]["postal"] = pcd or addr["home"]["postal"]
                addr["home"]["line"] = line or addr["home"]["line"]
            else:
                addr["other"]["postal"] = pcd or addr["other"]["postal"]
                addr["other"]["line"] = line or addr["other"]["line"]
        else:
            break

    return {
        "first": first, "middle": middle, "last": last,
        "pf_first": pf_first, "pf_middle": pf_middle, "pf_last": pf_last,
        "nickname": nickname, "notes": notes, "birthday": birthday,
        "org": org, "dept": dept, "title": title,
        "emails": emails, "phones": phones, "addrs": addr
    }

# =========================
# å®›åè·äººå‡ºåŠ›å‡¦ç†ï¼ˆä¿®æ­£ç‰ˆï¼‰
# =========================

def build_atena_row(g):
    last = g["last"]; first = g["first"]; middle = g["middle"]
    pf_last = g["pf_last"]; pf_first = g["pf_first"]; pf_middle = g["pf_middle"]
    nickname = g["nickname"]; notes = g["notes"]; birthday = g["birthday"]
    org = insert_space_after_corp_prefix(g["org"])
    dept = g["dept"]; title = g["title"]
    aw, ah, ao = g["addrs"]["work"], g["addrs"]["home"], g["addrs"]["other"]

    def pack_addr(line):
        base, bld = normalize_address(line)
        return base, bld

    w_base, w_bld = pack_addr(aw["line"])
    h_base, h_bld = pack_addr(ah["line"])
    o_base, o_bld = pack_addr(ao["line"])

    def join_and_hankaku(vals):
        vals = [normalize_for_phone_email_postal(v) for v in vals if v]
        return ";".join(v for v in vals if v)

    phone_work = join_and_hankaku(g["phones"]["work"])
    phone_home = join_and_hankaku(g["phones"]["home"])
    phone_other = join_and_hankaku(g["phones"]["other"])
    email_work = join_and_hankaku(g["emails"]["work"])
    email_home = join_and_hankaku(g["emails"]["home"])
    email_other = join_and_hankaku(g["emails"]["other"])

    postal_work = normalize_for_phone_email_postal(aw["postal"])
    postal_home = normalize_for_phone_email_postal(ah["postal"])
    postal_other = normalize_for_phone_email_postal(ao["postal"])

    last_k, first_k, middle_k = g["pf_last"], g["pf_first"], g["pf_middle"]
    atesaki = "ä¼šç¤¾" if org else "è‡ªå®…"

    # ğŸ‘‡ ä¿®æ­£ç‰ˆï¼šå§“åãƒ»å§“åã‹ãªã‚’ã€Œå§“ï¼‹åã€é †ã«ã™ã‚‹
    sei_mei = (last + "ã€€" + first).strip()
    sei_mei_kana = (last_k + "ã€€" + first_k).strip()

    def Z(x): return to_zenkaku(x or "")
    row = {"å§“": Z(last), "å": Z(first), "å§“ã‹ãª": Z(last_k), "åã‹ãª": Z(first_k),
           "å§“å": Z(sei_mei), "å§“åã‹ãª": Z(sei_mei_kana),
           "ä¼šç¤¾å": Z(org), "éƒ¨ç½²å1": Z(dept), "å½¹è·å": Z(title),
           "ä¼šç¤¾ä½æ‰€1": Z(w_base), "ä¼šç¤¾ä½æ‰€2": Z(w_bld),
           "ä¼šç¤¾ã€’": postal_work, "ä¼šç¤¾é›»è©±1ã€œ10": phone_work,
           "è‡ªå®…ä½æ‰€1": Z(h_base), "è‡ªå®…ä½æ‰€2": Z(h_bld),
           "è‡ªå®…ã€’": postal_home, "è‡ªå®…é›»è©±1ã€œ10": phone_home,
           "ãã®ä»–ä½æ‰€1": Z(o_base), "ãã®ä»–ä½æ‰€2": Z(o_bld),
           "ãã®ä»–ã€’": postal_other, "ãã®ä»–é›»è©±1ã€œ10": phone_other,
           "å‚™è€ƒ1": Z(notes), "èª•ç”Ÿæ—¥": Z(birthday)}
    return row

# =========================
# CSV I/O ã¨ Flaskã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =========================

def read_google_csv(file_bytes):
    for enc in ("utf-8", "utf-8-sig", "cp932", "shift_jis"):
        try:
            f = io.StringIO(file_bytes.decode(enc))
            r = csv.DictReader(f)
            rows = [{(k or "").strip(): (v or "") for k, v in row.items()} for row in r]
            return rows
        except Exception:
            continue
    raise ValueError("CSVèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")

@app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

@app.route("/convert", methods=["POST"])
def convert():
    if "file" not in request.files:
        abort(400, "file is required")
    data = request.files["file"].read()
    grows = read_google_csv(data)
    out_rows = [build_atena_row(parse_google_row(r)) for r in grows]

    buf = io.StringIO(newline="")
    writer = csv.DictWriter(buf, fieldnames=list(out_rows[0].keys()))
    writer.writeheader()
    writer.writerows(out_rows)
    return send_file(io.BytesIO(buf.getvalue().encode("utf-8-sig")),
                     mimetype="text/csv",
                     as_attachment=True,
                     download_name="google_converted.csv")

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5001))
    app.run(host="0.0.0.0", port=port)
